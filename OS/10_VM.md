[TOC]

# Basis

Dynamic Loading (Partially-loaded program)

* Save phy space
* speed up startup (only load necessary code)



Shared Lib: See [chap9](./9_MainMem.md).Paging.Page\\sSharing



å¦‚ä½•åˆ¤æ–­åœ°å€æ˜¯å¦åˆæ³•ï¼š

* kernelåˆ†é…ç»™è¿›ç¨‹logicalä¸Šçš„ç©ºé—´å¹¶maintain
* å¯¹åº”çš„physicalç©ºé—´çš„ç”³è¯·æ—¶ä¼šå…ˆæ£€æŸ¥logicalç©ºé—´æ˜¯å¦åˆæ³•
    * æ£€æŸ¥æ˜¯ç”±kernelåœ¨logicalçº§åˆ«è¿›è¡Œçš„

# ==Demand Paging==

==ä¸æ˜¯lab6ä¸­çš„==

## Basis

* Demand paging brings a page into memory only when it is accessed (å¯¹äºéœ€è¦swap inçš„å¤–å­˜ä¸Šçš„æ–‡ä»¶æ¥è¯´)
    * Situations
        1. if page is invalid â  abort the operation
        2. if page is valid but not in memory â  bring it to memory via swapping
    * no unnecessary I/O, less memory needed, faster response, more apps
* Lazy swapper: <u>never swaps a page in memory unless it will be needed</u>
    * the swapper that deals with pages is also caller a pager
    * å¥½å¤„ï¼šçœå†…å­˜
    * åå¤„ï¼šå¯èƒ½å¢å¤§ç¼ºé¡µå¯¼è‡´çš„å¼€é”€ï¼ˆä¾‹å¦‚codeæ®µï¼Œç¬¬ä¸€æ¬¡è¯»äº†ä¸€ä¸ªpageï¼Œç„¶åå‘ç°åˆšæ‰§è¡Œæ²¡å‡ æ¡æŒ‡ä»¤å°±è·³è½¬åˆ°ç¬¬äºŒä¸ªé¡µã€‚è€Œå¦‚æœä¸ä½¿ç”¨lazy swapperï¼Œåˆ™å¯ä»¥ä¸€æ¬¡swap inå¤šä¸ªé¡µ(ä¹‹åå¯èƒ½ç”¨ä¸Š)ï¼Œè¿™æ ·å¯ä»¥èŠ‚çœIOæ“ä½œçš„é™„å¸¦å¼€é”€ï¼ˆä½†æ˜¯ä¼ è¾“æœ¬èº«çš„å¼€é”€æ˜¯ä¸å˜æˆ–æ›´å¤§çš„ï¼‰
* Pre-Paging: pre-page all or some of pages a process will need, before they are referenced
    * it can reduce the number of page faults during execution
    * if pre-paged pages are unused, I/O and memory was wasted
        * although it reduces page faults, total I/O# likely is higher



**Valid-Invalid Bit**

Each page table entry has a validâ€“invalid (present) bit

* v â  in memory (memory is resident), i â  not-in-memory
    * ==è¿™é‡Œçš„invalidå’Œä¸Šé¢çš„ä¸ä¸€æ ·==
* initially, validâ€“invalid bit is set to i on all entries
* during address translation, if the entry is invalid, it will trigger a page fault

<img src="assets/image-20201126142517860.png" style="zoom: 33%;" />



## Page Fault

First reference to a non-present page will trap to kernel: page fault

* Operating system looks at memory mapping to decide:
    * invalid reference â  deliver an exception to the process
        * éœ€è¦ç¨‹åºè‡ªå·±æ³¨å†Œä¸€ä¸ªæ¥å—å‡½æ•°ï¼Œå†…æ ¸defaultçš„ä¼šç›´æ¥killè¿™ä¸ªè¿›ç¨‹
    * valid but not in memory â  swap in
        1. get an empty physical frame
        2. swap page into frame via disk operation
        3. set page table entry to indicate the page is now in memory
        4. <u>restart the instruction that caused the page fault</u>
* Handling
    * <img src="assets/image-20201127142748737.png" style="zoom: 33%;" />

**Pure Demand Paging**

* Extreme case: start process with no pages in memory (aka. pure demand paging)
    * OS sets instruction pointer to first instruction of process
        * invalid page â  page fault
    * every page is paged in on first access
        * program locality reduces the overhead
    * an instruction could access multiple pages â  multiple page faults
        * e.g., instruction, data, and page table entries for them
    * Demand paging needs hardware support
        * page table entries with valid / invalid bit
        * backing storage (usually disks)
        * instruction restart



**Instruction Restart**

å¯¹äºèƒ½æ”¹å˜å¤šä¸ªå†…å­˜åœ°å€çš„æŒ‡ä»¤ï¼ˆå¦‚å°†ä¸€ä¸ªblockä»ä¸€å¤„ç§»åˆ°å¦ä¸€å¤„ï¼‰ï¼Œå¦‚æœsrcå’Œdstçš„ä½ç½®æœ‰é‡å ï¼Œä¸”å…¶ä¸­ä»»ä¸€å—ä¼šè·¨è¶Šä¸¤ä¸ªé¡µå¹¶è§¦å‘page fault&swap inï¼Œè¿™æ—¶ä¸èƒ½ç®€å•åœ°redo instï¼Œå› ä¸ºsrcä¸­overlapçš„éƒ¨åˆ†å¯èƒ½å·²ç»è¢«æ”¹è¿‡äº†



**Free-Frame List**

* When a page fault occurs, the operating system must bring the desired page from secondary storage into main memory.
* Most operating systems maintain a free-frame list -- a pool of free frames for satisfying such requests.
* Operating system typically allocate free frames using a technique known as **zero-fill-on-demand** -- the content of the frames zeroed-out(å¡«å……0å»åˆå§‹åŒ–) before being allocated.
* When a system starts up, all available memory is placed on the free-frame list.



## Performance

### Steps

**Worse Case**

1. Trap to the operating system
2. Save the user registers and process state (å·²è¿›å…¥å¼‚å¸¸å¤„ç†å‡½æ•°ï¼Œå†…æ ¸æ€)
3. Determine that the interrupt was a page fault
4. Check that the page reference was legal and determine the location of the page on the disk
5. Issue a read from the disk to a free frame:
  1. Wait in a queue for this device until the read request is serviced
  2. Wait for the device seek and/or latency time
  3. Begin the transfer of the page to a free frame
6. While waiting, allocate the CPU to some other user (å›åˆ°ç”¨æˆ·æ€)
7. Receive an interrupt from the disk I/O subsystem (I/O completed)
8. Save the registers and process state for the other user (å·²è¿›å…¥å¼‚å¸¸å¤„ç†å‡½æ•°ï¼Œå†…æ ¸æ€))
9. Determine that the interrupt was from the disk
10. Correct the page table and other tables to show page is now in memory
11. Wait for the CPU to be allocated to this process again
12. Restore the user registers, process state, and new page table, and then resume the interrupted instruction (è¿™é‡Œæ˜¯å›åˆ°ç¬¬6æ­¥ä¸­çš„å¦ä¸€ä¸ªè¿›ç¨‹ï¼Œä¼šç»§ç»­æ‰§è¡Œç›´åˆ°cnt=0)

### EAT

* Page fault rate: 0 â‰¤ p â‰¤ 1
* Effective Access Time (EAT):
    `(1 â€“ p) x memory access + p x (page_fault_overhead + swap_page_out + swap_page_in + instruction_restart_overhead)`

### Opt

* Swap space I/O faster than file system I/O even if on the same device
    * Swap allocated in larger chunks, less management needed than file system
* Copy entire process image to swap space at process load time
    * Then page in and out of swap space
    * Used in older BSD Unix
* Demand page in from program binary on disk, but discard rather than paging out when freeing frame (and reload from disk next time)
    * Still need to write to swap space
        * Pages not associated with a file (like stack and heap) â€“ anonymous memory
        * Pages modified in memory but not yet written back to the file system
* Mobile systems
    * Typically donâ€™t support swapping
    * è§[chap9](./9_MainMem.md)
    * Instead, demand page from file system and reclaim read-only pages (such as code)

# ==COW==

forkå­è¿›ç¨‹æ—¶ä¸æ‹·è´æ•°æ®ï¼Œä»…æœ‰å†™æ“ä½œæ—¶æ‰å»æ‹·è´

* Copy-on-write (COW) allows parent and child processes to initially share the same pages in memory
    * the page is shared as long as no process modifies it
    * if either process modifies a shared page, only then is the page copied
* COW allows more ==efficient== process ==creation==
    * no need to copy the parent memory during fork
    * only changed memory will be copied later
* vfork(è€å¼åµŒå…¥è®¾å¤‡ä½¿ç”¨) syscall optimizes the case that child calls exec immediately after fork (å‡è®¾forkå®Œï¼Œå­è¿›ç¨‹é©¬ä¸Šä¼šè°ƒç”¨execå‡½æ•°)
    * parent is suspend until child exits or calls exec
    * child shares the parent resource, including the heap and the stack (ç”±ç¨‹åºå‘˜ä¿è¯ä¸ä¿®æ”¹ï¼Œæ²¡æœ‰åº•å±‚æ£€æŸ¥)
        * child cannot return from the function or call exit
    * vfork could be fragile, it is invented when COW has not been implemented

# Page Replacement

* Memory is an important resource, system may run out of memory
* To prevent out-of-memory, swap out some pages
    * page replacement usually is a part of the page fault handler
    * policies to select victim page require careful design
        * need to reduce overhead and avoid thrashing
    * <u>use modified (dirty) bit to reduce number of pages to swap out</u>
        * only modified pages are written to disk
    * select some processes to kill (last resort)
* Page replacement completes separation between logical memory and physical memory â€“ large virtual memory can be provided on a smaller physical memory



2 I/Os for an page fault

## Algorithm

### Evaluation

1. run it on a particular string of memory references (reference string)
    * string is just page numbers, not full addresses
    * in all our examples, the ==reference string== is `7,0,1,2,0,3,0,4,2,3,0,3,0,3,2,1,2,0,1,7,0,1`
2. compute <u>the number of page faults on that string</u>
    * repeated access to the same page does not cause a page fault

### FIFO Alg

* FIFO: replace the first page loaded
    * similar to sliding a window of n in the reference string
    * our reference string will cause 15 page faults with 3 frames
    * how about reference string of 1,2,3,4,1,2,5,1,2,3,4,5 /w 3 or 4 frames?
* <u>**Belady's Anomaly**: For FIFO, adding more frames can cause more page faults!</u>
    * Framesæ•°ä¸PFæ•°ä¸ä¸€å®šå®Œå…¨è´Ÿç›¸å…³
* å‰ä¸‰æ¬¡å¿…ç¼ºé¡µ

### Optimal Alg

* Optimal(æœ€ä¼˜): replace page that <u>**will** not be used for the longest time</u>
    * æ˜¯ä¸ªé¢„æµ‹
    * 9 page fault is optimal for the example on the next slide
* How do you know which page will not be used for the longest time?
    * canâ€™t read the future
    * used for measuring how well your algorithm performs

### LRU Alg

LRUå’ŒOPT(æœ€ä¼˜)æ²¡æœ‰Beladyâ€™s Anomaly

LRUæ˜¯å¯¹OPTçš„approximation

* LRU replaces pages that have not been used for the longest time
    * associate time of last use with each page, select pages w/ oldest timestamp
    * generally good algorithm and frequently used
    * 12 faults for our example, better than FIFO but worse than OPT



**2 implementation**

(ç†è®ºå®ç°ï¼Œå®é™…å¹¶ä¸)

* Counter-based implementation
    * every page table entry has a counter
    * every time page is referenced, copy the clock into the counter
    * when a page needs to be replaced, search for page with smallest counter
        * <u>min-heap</u> can be used
* Stack-based implementation
    * keep a stack of page numbers (in double linked list)
    * when a page is referenced, move it to the top of the stack
    * each update is more expensive, but no need to search for replacement
    * ç”±äºæ¶‰åŠåˆ°å…ƒç´ çš„æ’å…¥ï¼Œå› æ­¤å¯ä»¥ç”¨é“¾è¡¨å®ç°



### LRU Approx Alg

* Counter-based and stack-based LRU have high performance overhead
* Hardware provides a reference bit
* LRU approximation with a reference bit
    * associate with each page a reference bit, initially set to 0
    * when page is referenced, set the bit to 1 (done by the hardware)
    * replace any page with reference bit = 0 (if one exists)
        * We do not know the order, however

#### Additional-Reference-Bits

Reordering the bits at regular intervals

* Suppose we have 8-bits byte for each page
* During a time interval (100ms), <u>sets the high bit and shifts bit rights by 1 bit</u>, and then discards the low-order bits
* 00000000 => has not been used in 8 time intervals
* 11111111 => has been used in all time intervals

å› ä¸ºæ˜¯å³ç§»ï¼Œæ‰€ä»¥æœ€é«˜ä½æ˜¯æœ€æ–°çš„



\>ï¼Ÿåˆšæ¢è¿›æ¥çš„åªæœ‰ä¸€æ¬¡referenceï¼Œé‚£ä¸æ˜¯åˆšæ¢è¿›æ¥å°±å‡ºå»çš„æ¦‚ç‡å¾ˆé«˜ï¼Ÿæ˜¯ç›´æ¥çœ‹å¤§å°è€Œä¸æ˜¯çœ‹å„ä½bitä¹‹å’Œï¼Œæ‰€ä»¥å…¶å®æ˜¯æœ€å¤§çš„ï¼Œå› ä¸ºå…¶ä»–çš„æœ€é«˜ä½å…¨æ˜¯0ã€‚



#### Second-chance

* Generally FIFO, plus hardware-provided reference bit
* Clock replacement
* If page to be replaced has
    * Reference bit = 0 -> replace it
    * reference bit = 1 then:
        1. set reference bit 0, leave page in memory
        2. ~~replace~~ skip to next page, subject to same rules

é¿å…reference bitè®°å½•äº†å¤ªé•¿æ—¶é—´çš„ä¿¡æ¯ï¼ˆè¿™æ ·åŸºæœ¬ä¸Šå…¨æ˜¯1ï¼‰ï¼Œéå†ä¸€éPTå»æ‰¾0å¼€é”€å°±å¾ˆå¤§

#### Enhanced SC

* Improve algorithm by using <u>reference</u> bit and <u>modify</u> bit (if available) in concert
* Take ordered pair <u>(reference, modify)</u>:
    * (0, 0) neither recently used nor modified â€“ best page to replace
    * (0, 1) not recently used but modified â€“ not quite as good, must write out before replacement
    * (1, 0) recently used but clean â€“ probably will be used again soon
    * (1, 1) recently used and modified â€“ probably will be used again soon and need to write out before replacement
* When page replacement called for, use the clock scheme but use the four classes replace page in lowest non-empty class
    * Might need to search circular queue several times

### Page-Buffering Alg

(Counting-based Page Replacement omitted

å¹¶ä¸æ˜¯ä¸ªé€‰æ‹©ç‰ºç‰²å¸§çš„ç®—æ³•

* Keep a pool of free frames, always
    * Then frame available when needed, not found at fault time
    * Read page( from from buffer pool???) into free frames without waiting for victims(ä½¿ç”¨å‰é¢çš„ç®—æ³•æ¥å¾—åˆ°) to write out
        * Restart as soon as possible
    * When convenient, evict victim (victimä¹‹åæ…¢æ…¢swap outï¼Œç„¶åå†æ ‡è®°ä¸ºfree)
* Possibly, keep list of modified pages
    * When backing store otherwise idle, write pages there and set to non-dirty: this page can be replaced without writing pages to backing store
* Possibly, keep free frame contents intact and note what is in them - a kind of cache
    * If referenced again before reused, no need to load contents again from disk
        * cache hit

# Frame Alloc

* Each process needs minimum number of frames -according to instructions semantics
* Example: IBM 370 â€“ 6 pages to handle SS MOVE instruction:
    * instruction is 6 bytes, might span 2 pages
    * 2 pages to handle from
    * 2 pages to handle to
* Maximum of course is total frames in the system



## Allocation schemes

* fixed allocation
    * Equal allocation â€“ For example, if there are 100 frames (after allocating frames for the OS) and 5 processes, give each process 20 frames
        * Keep some as free frame buffer pool
    * Proportional allocation â€“ Allocate <u>according to the size</u> of process
        * Dynamic as degree of multiprogramming, process sizes change
* priority allocation

* Many variations

## Global/Local Alloc

* Global replacement â€“ process selects a replacement frame from the set of all frames; <u>one process can take a frame from another</u>
    * But then process execution time can vary greatly - depends on others
    * But greater throughput so more common
    * ç›®å‰ä¸»æµ
* Local replacement â€“ each process selects from only its <u>own set of allocated frames</u>
    * More consistent per-process performance
    * But possibly underutilized memory

## Reclaiming Pages

* A strategy to implement global page-replacement policy
* All memory requests are satisfied from the free-frame list, <u>rather than waiting for the list to drop to zero before we begin selecting pages for replacement</u>
* Page replacement is triggered when the list falls below a certain
    threshold.
* This strategy attempts to ensure there is always sufficient free
    memory to satisfy new requests.



å¦‚æœå†…å­˜æ¯”ä¸‹é™è¿˜å°‘ï¼Œå°±ä¼šReclaim pages aggressively

* Kill some processes
* [OOM score](https://serverfault.com/questions/571319/how-is-kernel-oom-score-calculated)



**Major and minor page faults**

* Major: page is referenced but not in memory (éœ€è¦è¿›è¾…å­˜)
* Minor: mapping does not exist, <u>but the page is in memory</u> (ä¸éœ€è¦è¿›è¾…å­˜)
    * Shared library
    * Reclaimed and not freed yet

```zsh
$ ps eo min_flt,maj_flt,cmd
 MINFL  MAJFL CMD
   689     31 /bin/bash PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=10a3bea4265b TERM=xte
  1811      0 bash PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=10a3bea4265b TERM=xterm HO
   775      0 bash PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin HOSTNAME=10a3bea4265b TERM=xterm HO
  6009      0 -zsh HOSTTYPE=x86_64 LANG=C.UTF-8 PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/g
   194      0 ps eo min_flt,maj_flt,cmd HOSTTYPE=x86_64 LANG=C.UTF-8 PATH=/home/ulysses/anaconda3/condabin:/usr/local/sb
```

## Special: NUMA

Non-Uniform Memory Access

* So far all memory accessed equally
* Many systems are NUMA â€“ speed of access to memory varies
    * Consider system boards containing CPUs and memory, interconnected over a system bus
* NUMA multiprocessing architecture
* Optimal performance comes from <u>allocating memory â€œclose toâ€ the CPU on which the thread is scheduled</u>
    * And modifying the scheduler to <u>schedule the thread on the same system board</u> when possible
    * Linux
        * Kernel maintains scheduling domains: does not allow threads to migrate across domains
        * A separate free-frame list for each NUMA node - allocating memory from the node it is running

# ~~Thrashing~~

## ~~Reasons~~

* If a process doesnâ€™t have â€œenoughâ€ pages, page-fault rate may be high
    * page fault to get page, replace some existing frame
    * <u>but quickly need replaced frame back</u> (æˆ‘æœ‰10ä¸ªé¡µæ˜¯å¸¸ç”¨çš„ï¼Œç„¶è€Œåªæœ‰5ä¸ªé¡µçš„ç©ºé—´)
    * this leads to:
        * low CPU utilization â  kernel thinks it needs to increase the degree of multiprogramming to maximize CPU utilization â  another process added to the system
        * æ¶æ€§å¾ªç¯
* Def: <u>Thrashing: a process is busy swapping pages in and out</u>

<img src="assets/image-20201130160228298.png" style="zoom:50%;" />



**Demand Paging and Thrashing**

* Why does demand paging work?
    * process memory access has high locality
    * process migrates from one locality to another(ä¸åŒæ—¶é—´éƒ½æœ‰localityï¼Œä½†æ˜¯locationä¸ä¸€æ ·), localities may overlap
* Why does thrashing occur?
    * <u>total size of locality > total memory size</u>



**Option**

1. Limit thrashing effects by using local or priority page replacement
    * One process starts thrashing does not affect others -> it cannot cause other processes thrashing
2. Provide a process with as many frames as it needs.
    * total memory size < total size of locality
    * needs
        1. è¶³å¤Ÿçš„ç©ºé—´
        2. èƒ½å¤Ÿé¢„æµ‹total size of locality



## ~~Working-set Model~~

* Working-set window(Î”): a fixed number of page references (æ£€æŸ¥æœ€è¿‘Î”ä¸ªpagesçš„å¼•ç”¨)
    * if Î” too small â  will not encompass entire localityï¼ˆä¸€ä¸ªå±€éƒ¨éƒ½ä¸å¤Ÿï¼‰
    * if Î” too large â  will encompass several localitiesï¼ˆåŒ…å«äº†å¤šä¸ªå±€éƒ¨ï¼Œä¼°è®¡å¼€å§‹ä¸å‡†ç¡®äº†ï¼‰
    * if Î” = âˆ â  will encompass entire programï¼ˆè¿›ç¨‹æ‰§è¡Œæ‰€æ¥è§¦åˆ°çš„æ‰€æœ‰é¡µçš„é›†åˆï¼‰
* Working set of <u>process</u> pi (WSSi): total number of pages referenced in the most recent Î” (varies in time)
* Total working sets( of system): D = Î£WSS~i~
    * approximation of total locality
    * if D > m â  possibility(å–å†³äºé¢„æµ‹çš„å‡†ç¡®æ€§) of thrashing
    * to avoid thrashing: if D > m, suspend or swap out some processes



**Tracking of the WS**

Î”=10000ï¼Œæ¯5000ä¸ªå¼•ç”¨ä¼šæœ‰ä¸€æ¬¡ä¸­æ–­ï¼Œå¯¹äºæ¯ä¸ªé¡µï¼Œæœ¬èº«æœ‰ä¸€ä¸ªå¼•ç”¨ä½ï¼Œå†…å­˜ä¸­æ”¾10000/5000=2ä¸ªé¢å¤–ä½

* æ¯å½“æœ‰ä¸­æ–­ï¼Œå…ˆå°†å¼•ç”¨ä½æ‹·è´åˆ°å†…å­˜ï¼Œç„¶åæ¸…é›¶
* å¦‚æœå†…å­˜ä¸­æœ‰ä¸€ä¸ªä¸ºæ˜¯1ï¼Œå°±è¡¨æ˜è¿™ä¸ªpageåœ¨working seté‡Œ
* é—®é¢˜ï¼šèƒ½çŸ¥é“æ˜¯åœ¨1-5000è¿˜æ˜¯5001-10000ï¼Œä½†æ˜¯ä¸çŸ¥é“æ›´å…·ä½“çš„
* è§£å†³ï¼šæ¯1000ä¸ªå¼•ç”¨ä¸€æ¬¡ä¸­æ–­ï¼Œå†…å­˜ä¸­10ä¸ªä½ï¼Œè¿™æ ·å°±å¯ä»¥ç²¾ç¡®åˆ°1000æ¬¡å¼•ç”¨
    * é—®é¢˜ï¼šæ›´å¤šä¸­æ–­ã€æ›´å¤šå†…å­˜



**Working Sets and Page Fault Rates**

* Assumes there is no thrashing
* Direct relationship between working set of a process and its page-fault rate
* Working set changes over time
* Peaks and valleys over time



## ~~Page-Fault Frequency~~

* More direct approach than WSS
* Establish â€œacceptableâ€ page-fault frequency (PFF) rate
    * If actual rate too low, process loses frame
    * If actual rate too high, process gains frame
* Need to swap out a process if no free fames are available
* ![](assets/image-20201130164430972.png)



# Kernel MemAlloc

* Kernel memory allocation is treated differently from user
    memory, it is often allocated from a free-memory pool
    * kernel requests memory for structures of varying sizes
        -> minimize waste due to fragmentation
    * Some kernel memory needs to be physically
        contiguous
        * e.g., for device I/O
            * DMAï¼šDMAæ˜¯è„±ç¦»äº†CPUç›´æ¥æ“ä½œç‰©ç†å†…å­˜çš„ï¼Œç”±äºå…¶æ˜¯å¯¹æ•´å—å†…å­˜çš„æ¬è¿ï¼Œå› æ­¤å¦‚æœç‰©ç†åœ°å€ä¸è¿ç»­å°±ä¼šé”™



## Buddy System

* Memory allocated using power-of-2 allocator
    * memory is allocated in units of the size of power of 2
        * round up a request to the closest allocation unit
        * split the unit into two â€œbuddiesâ€ until a proper sized chunk is available
    * e.g., assume only 256KB chunk is available, kernel requests 21KB
        * split it into Al and Ar of 128KB each
        * further split an 128KB chunk into Bl and Br of 64KB
        * again, split a 64KB chunk into Cl and Cr of 32KB each
        * give one chunk for the request
* advantage: it can quickly coalesce unused chunks into larger chunk
* disadvantage: <u>internal fragmentation</u>
    * 33k request -> 64k segment

è¿™è¿ç»­çš„256Kæ€ä¹ˆåˆ†é…çš„ï¼Ÿå®é™…ä¸Šä¹Ÿæ˜¯å»free-frame list(pool)æ‰¾å¤šä¸ªè¿ç»­çš„é¡µå‡‘åœ¨ä¸€èµ·çš„

```mermaid
graph TB
256K-->Al[Al:128K]-->Bl[Bl:64K]-->Cl[Cl:32K]
256K-->Ar[Ar:128K]
Al-->Br[Br:64K]
Bl-->Cr[Cr:32K]
```



## Slab Allocator (ä¸è€ƒ)

https://www.kernel.org/doc/gorman/html/understand/understand011.html

* Slab allocator is a cache of objects
    * a cache in a slab allocator consists of one or more slabs
    * a Slab contains one or more pages, divided into equal-sized objects
    * kernel uses one cache for each unique kernel data structure
        * when cache created, allocate a slab, divided the slab into free objects
        * objects for the data structure is allocated from free objects in the slab
        * if a slab is full of used objects, next object comes from an empty/new slab
    * å¤§æ¦‚æ˜ç™½äº†ï¼Œå°±æ˜¯ä¸€ä¸ªå°†ä¸€ä¸ªç‰©ç†çš„pageï¼ˆä¾‹å¦‚4Kï¼‰åˆ†æˆå¾ˆå¤šå¾ˆå¤šä¸ªcacheï¼ˆå¤§æ¦‚32Bytesï¼Œç‰©ç†ä¸Šæ˜¯memï¼‰ï¼Œé‡Œé¢å­˜ç±»ä¼¼mm_struct, task_structè¿™æ ·çš„structï¼Œç„¶åé‡Œé¢ä¼šæœ‰å„ç§å‚æ•°ï¼Œæ˜¯è®°å½•å¤–é¢å†…å­˜é‡Œçš„ä¸œè¥¿ï¼ˆprocessï¼‰ä¹‹ç±»çš„å±æ€§çš„ï¼Œå› ä¸ºè¿™äº›å‚æ•°å°±åŒ…æ‹¬äº†base, limitä¹‹ç±»çš„æ•°æ®ï¼Œå› æ­¤ä¸ç”¨åƒbuddyä¸€æ ·ä¸€å®šè¦æ˜¯power of 2çš„å¤§å°äº†
* Benefits: <u>no fragmentation</u> and fast memory allocation
    * ä¸ä¸€å®šå®Œå…¨æ²¡æœ‰å†…éƒ¨ç¢ç‰‡åŒ–ï¼Œslabæœ¬èº«æ˜¯æ²¡æœ‰ç¢ç‰‡åŒ–çš„ï¼Œä½†æ˜¯slab allocatorä¼šæœ‰ï¼Œä¾‹å¦‚`struct a {int a; char b[20];}`æ˜¯24 bytesçš„ï¼Œä½†æ˜¯ä¼šè¢«åˆ†é…32 bytesçš„ç©ºé—´
    * some of the object fields may be reusable; no need to initialize again
* <img src="assets/image-20201130171807485.png" style="zoom:67%;" />



**Slab Allocator in Linux**

* For example process descriptor is of type struct task_struct
    * Approx 1.7KB of memory
    * New task -> allocate new struct from cache
        * Will use existing free struct task_struct
* A Slab can be in three possible states
    * Full â€“ all used
    * Empty â€“ all free
    * Partial â€“ mix of free and used
* Upon request, slab allocator
    1. Uses free struct in partial slab
    2. If none, takes one from empty slab
    3. If no empty slab, create new empty



# Other Considerations

* Prepaging
    * å†·å¯åŠ¨å¾ˆæ…¢ï¼Œå¯ä»¥æå‰å†™è¿›å»
* Page size
    * Page size selection must take into consideration:
        â€¢ Fragmentation -> small page size
        â€¢ Page table size -> large page size
        â€¢ Resolution -> small page size
        â€¢ I/O overhead -> large page size
        â€¢ Number of page faults -> large page size
        â€¢ Locality -> small page size
        â€¢ TLB size and effectiveness -> large page size
    * Usally 2^12^ \~ 2^22^ (4K \~ 4M)
* TLB reach
    * é€šè¿‡æ‰€æœ‰TLBå¯ä»¥è®¿é—®åˆ°çš„memçš„å¤§å°
* Inverted page table
* Program structure
    * `for i; for j;`å’Œ`for j; for i;`
* I/O interlock and page locking
    * Pages must sometimes be locked into memory



# ~~Linux~~

[courseware](../../OS/CW/10_Linux_virtual_memory.pdf)

API func

```mermaid
graph TB

0[<b>Some kernel Code</b>]
1[<b>`kmalloc` Allocator</b><br />Uses a set of anonymous SLAB caches]
2[<b>`vmalloc` Allocator</b><br />Non-physically contiguous memory]
3[<b>SLAB Allocator</b><br />Allows to create caches, each cache storing<br />objects of the same size.<br />Size can be lower or greater than a page size]
4[<b>Page Allocator</b><br />Allows a allocate contiguous areas of physical pages,<br />e.g. 4k, 8k, 16k, etc.]

0-->1-->3-->4
0-->3-->4
0-->4
0-->2-->4
```



**3 kinds of Virtual Address**

1. Kernel Logical Address
2. Kernel Virtual Address
3. Usersapce Virtual Address

 

å†…æ ¸æ€åœ¨physicalä¸Šä»0å¼€å§‹ï¼Œæ‰€ä»¥å®é™…ä¸ŠKernel Logical Addr --> physical addrçš„è½¬æ¢ç›´æ¥å‡0xC0000000å°±è¡Œ

* å¦‚æœæ˜¯å°å†…å­˜çš„æœºå™¨ï¼ˆ<1GBï¼‰ï¼Œå°±å¦å¤–æœ‰ä¸ªKernel Virtual Addrç”¨äºä¸è¿ç»­çš„å†…æ ¸æ•°æ®çš„mapping
* å¦‚æœæ˜¯å†…å­˜éå¸¸å¤§çš„æœºå™¨ï¼Œphysicalä¸Šåªæœ‰ä¸€éƒ¨åˆ†ç”¨äºå­˜æ•´ä¸ªå†…æ ¸æ•°æ®ï¼ˆç•™ä¸‹96è¿˜æ˜¯128MB<!--zyjå¿˜äº†-->ç»™Kernel Virtual Addressï¼‰



![](assets/image-20201130153535093.png)

## Confuse

Virtual/Logical: what's th diff

Linear

Physical

# ~~Buffer Overflow~~

stack frameæ˜¯func-uniqueçš„ï¼Œframe pointeræ˜¯æŒ‡å‘è¿™ä¸ªæ ˆçš„æ ˆåº•çš„æŒ‡é’ˆ

```assembly
# i386é‡Œebqæ˜¯frame pointer

# è°ƒç”¨æ—¶çš„æ ˆåˆ‡æ¢
push %ebp       # å­˜ä½ä¸Šä¸€ä¸ªå‡½æ•°çš„æ ˆåº•
mov %esp, %ebp  # ç”¨ä¸Šä¸€ä¸ªå‡½æ•°çš„æ ˆé¡¶ä½œä¸ºå½“å‰çš„æ ˆåº•

# `leave` macro
mov %ebp, %esp
pop %ebp

# `ret` macro
pop %eip        # cs:ip <-- return_addr
```



`objdump -S a.out > dasm.txt`



ä¸¤ç§å®‰å…¨æ€§é—®é¢˜

* bug
* vulnerability



Consequence: the buffer will overwrite the return address!
â€¢ case I: the overwritten return address is invalid -> crash (why?)
â€¢ Case II: the overwritten return address is valid but in kernel space
â€¢ Case III: the overwritten return address is valid, but points to data
â€¢ Case IV: the overwritten return address happens to be a valid one



## Overflow case

![](assets/image-20201207142655399.png)

* gcc -z stackexec
* åœ¨æ¶æ„ä»£ç å‰æ’å…¥nopï¼Œå¢å¤§å‘½ä¸­ç‡ï¼ˆå¦‚æœæ²¡æœ‰å¯èƒ½ä¼šå› ä¸ºinvalid instè§¦å‘å¼‚å¸¸ï¼‰

### Sol

* Use ASLRï¼Œè¿™æ ·æ¯æ¬¡æ¶æ„ä»£ç çš„ä½ç½®éƒ½ä¸€æ ·äº†ï¼Œå¯ä»¥ä¸€å®šç¨‹åº¦ä¸Šå¢åŠ å®‰å…¨æ€§ï¼Œä½†æ˜¯BFè¿˜æ˜¯å¾ˆå¥½ç ´è§£
* Use stack guardï¼Œåœ¨local varå’Œret valueä¹‹é—´åŠ ä¸€ä¸ªstack guardï¼Œå€¼æ˜¯ç”±ç¼–è¯‘å™¨æŒ‡å®šçš„ï¼Œå¤‡ä»½åœ¨å¦ä¸€ä¸ªä½ç½®ï¼Œè¿è¡Œæ—¶æ£€æŸ¥å®ƒçš„å€¼ï¼Œå¦‚æœå’Œå¤‡ä»½ä¸ä¸€æ ·å°±è¯´æ˜æ ˆè¢«ä¿®æ”¹äº†ï¼Œç›´æ¥abortæ•´ä¸ªè¿›ç¨‹
    * æ— æ³•è§£å†³data-onlyï¼ˆæ²¡æœ‰ä¿®æ”¹æ§åˆ¶æµï¼Œè€Œæ˜¯é€šè¿‡ä¿®æ”¹æŸä¸ªé‡è¦å˜é‡å½±å“äº†ç¨‹åºçš„è¿è¡Œï¼‰çš„æƒ…å†µ

# ~~Dirty COW~~

## mmap

```c
#include <sys/mman.h>
void *mmap(void *addr, size_t length, int prot, int flags,
           int fd, off_t offset);
int munmap(void *addr, size_t length);
```

If *<u>addr</u>* is NULL, then the kernel chooses the address at which to create the mapping; this is the most portable method of creating a new mapping. If *addr* is not NULL, then the kernel takes it as a hint about where to place the mapping; on Linux, the mapping will be created at a nearby page boundary. The address of the new mapping is returned as the result of the call.

The contents of a file mapping (as opposed to an anonymous mapping; see MAP_ANONYMOUS below), are initialized using *<u>length</u>* bytes starting at offset *<u>offset</u>* in the file (or other object) referred to by the file descriptor *<u>fd</u>*. *<u>offset</u>* must be a multiple of the page size as returned by sysconf(_SC_PAGE_SIZE).

The *<u>prot</u>* argument describes the <u>desired memory protection</u> of the mapping (and must not conflict with the open mode of the file). It is either PROT_NONE or the bitwise OR of one or more of the following flags:

* PROT_EXEC Pages may be executed.
* PROT_READ Pages may be read.
* PROT_WRITE Pages may be written.
* PROT_NONE Pages may not be accessed.

The *<u>flags</u>* argument determines <u>whether updates to the mapping are visible to other processes mapping the same region</u>, and <u>whether updates are carried through to the underlying file</u>. This behavior is determined by including exactly one of the following values in *<u>flags</u>*:

* MAP_SHARED
    * Share this mapping. Updates to the mapping are visible to other processes mapping the same region, and (in the case of file-backed mappings) are carried through to the underlying file. (To precisely control when updates are carried through to the underlying file requires the use of msync(2).)
* MAP_PRIVATE
    * Create a private copy-on-write mapping. Updates to the mapping are not visible to other processes mapping the same file, and are not carried through to the underlying file. It is unspecified whether changes made to the file after the mmap() call are visible in the mapped region.
* ![](assets/image-20201207144011365.png)
    * a: SHARED, b: PRIVATE

æœ¬æ¥ROçš„æ–‡ä»¶é€šè¿‡PRIVATEæ‰“å¼€æ˜¯saveçš„ï¼Œå› ä¸ºä¼šæœ‰cowï¼Œæ‰€ä»¥æ˜ å°„çš„å†…å­˜çš„ä¸œè¥¿ä¼šè¢«ä¿®æ”¹ï¼Œä½†æ˜¯æ–‡ä»¶ä¸ä¼šè¢«ä¿®æ”¹ã€‚ä½†æ˜¯ğŸ‘‡

**madvise**å¯ä»¥é€šè¿‡å°†RO(MAP_PRIVATE)çš„æ–‡ä»¶æ˜ å°„çš„æŒ‡é’ˆæŒ‡å‘cowä¹‹å‰çš„å†…å­˜çš„åœ°å€ï¼Œå°±å¯ä»¥å‘é‡Œé¢å†™ä¸œè¥¿äº†ï¼ˆæ¯”å¦‚å¯ä»¥ç”¨æ™®é€šç”¨æˆ·å»ä¿®æ”¹"/etc/passwd"ï¼ŒæŠŠè‡ªå·±çš„UIDæ”¹æˆ0ï¼Œç›´æ¥ææƒï¼Œä½†æ˜¯zyjæ˜¯åœ¨Ubuntu12ä¸Šæ“ä½œçš„ï¼Œæ‰€ä»¥å¯èƒ½æ–°ç‰ˆä¿®å¤äº†è¿™ä¸ªé—®é¢˜

